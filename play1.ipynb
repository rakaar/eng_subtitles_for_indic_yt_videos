{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARVAM_KEY = os.getenv('SARVAM_KEY')\n",
    "youtube_link = \"https://www.youtube.com/watch?v=PM1mT4AYyCc\"  # Replace with your YouTube video URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Youtube vid's audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_audio(url, output_path='downloads', audio_format='mp3'):\n",
    "    \"\"\"\n",
    "    Downloads audio from a YouTube video.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the YouTube video.\n",
    "    - output_path (str): The directory where the audio will be saved.\n",
    "    - audio_format (str): The desired audio format (e.g., 'mp3', 'm4a').\n",
    "\n",
    "    Returns:\n",
    "    - str: The path to the downloaded audio file.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Set up yt_dlp options\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',  # Select the best available audio quality\n",
    "        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),  # Output template\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',  # Extract audio using FFmpeg\n",
    "            'preferredcodec': audio_format,  # Desired audio format\n",
    "            'preferredquality': '192',  # Audio quality\n",
    "        }],\n",
    "        'quiet': False,  # Set to True to suppress output\n",
    "        'noplaylist': True,  # Only download single video, not playlist\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        try:\n",
    "            # Extract information and download\n",
    "            info_dict = ydl.extract_info(url, download=True)\n",
    "            \n",
    "            # Prepare the filename\n",
    "            filename = ydl.prepare_filename(info_dict)\n",
    "            base, _ = os.path.splitext(filename)\n",
    "            audio_file = f\"{base}.{audio_format}\"\n",
    "            \n",
    "            print(f\"Audio downloaded successfully: {audio_file}\")\n",
    "            return audio_file\n",
    "        except yt_dlp.utils.DownloadError as e:\n",
    "            print(f\"Error downloading audio: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=PM1mT4AYyCc\n",
      "[youtube] PM1mT4AYyCc: Downloading webpage\n",
      "[youtube] PM1mT4AYyCc: Downloading ios player API JSON\n",
      "[youtube] PM1mT4AYyCc: Downloading web creator player API JSON\n",
      "[youtube] PM1mT4AYyCc: Downloading player e38bb6de\n",
      "[youtube] PM1mT4AYyCc: Downloading m3u8 information\n",
      "[info] PM1mT4AYyCc: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_files/Nani's special & powerful characters ｜ nani ｜ vithin-cine.webm\n",
      "[download] 100% of    3.48MiB in 00:00:00 at 14.87MiB/s  \n",
      "[ExtractAudio] Destination: audio_files/Nani's special & powerful characters ｜ nani ｜ vithin-cine.mp3\n",
      "Deleting original file audio_files/Nani's special & powerful characters ｜ nani ｜ vithin-cine.webm (pass -k to keep)\n",
      "Audio downloaded successfully: audio_files/Nani's special & powerful characters ｜ nani ｜ vithin-cine.mp3\n",
      "Downloaded audio file path: audio_files/Nani's special & powerful characters ｜ nani ｜ vithin-cine.mp3\n"
     ]
    }
   ],
   "source": [
    "downloaded_audio = download_youtube_audio(youtube_link, output_path='audio_files', audio_format='mp3')\n",
    "if downloaded_audio:\n",
    "    print(f\"Downloaded audio file path: {downloaded_audio}\")\n",
    "else:\n",
    "    print(\"Failed to download audio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract first few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def extract_first_15_seconds(input_audio_path, output_audio_path='extracted_audio', duration_seconds=15, audio_format='mp3'):\n",
    "    \"\"\"\n",
    "    Extracts the first 15 seconds of an audio file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_audio_path (str): Path to the input audio file.\n",
    "    - output_audio_path (str): Directory where the extracted audio will be saved.\n",
    "    - duration_seconds (int): Duration to extract in seconds. Defaults to 15.\n",
    "    - audio_format (str): Format of the output audio file. Defaults to 'mp3'.\n",
    "\n",
    "    Returns:\n",
    "    - str: Path to the extracted audio file.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_audio_path, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio = AudioSegment.from_file(input_audio_path)\n",
    "        \n",
    "        # Extract the first 'duration_seconds' seconds\n",
    "        extracted_audio = audio[:duration_seconds * 1000]  # pydub works in milliseconds\n",
    "        \n",
    "        # Prepare the output file path\n",
    "        base = os.path.basename(input_audio_path)\n",
    "        name, _ = os.path.splitext(base)\n",
    "        output_file = os.path.join(output_audio_path, f\"{name}_first_{duration_seconds}s.{audio_format}\")\n",
    "        \n",
    "        # Export the extracted audio\n",
    "        extracted_audio.export(output_file, format=audio_format)\n",
    "        \n",
    "        print(f\"Extracted first {duration_seconds} seconds: {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted first 15 seconds: extracted_audio/Nani's special & powerful characters ｜ nani ｜ vithin-cine_first_15s.mp3\n",
      "Extracted audio file path: extracted_audio/Nani's special & powerful characters ｜ nani ｜ vithin-cine_first_15s.mp3\n"
     ]
    }
   ],
   "source": [
    "if downloaded_audio:\n",
    "    extracted_audio = extract_first_15_seconds(\n",
    "        downloaded_audio,\n",
    "        output_audio_path='extracted_audio',\n",
    "        duration_seconds=15,\n",
    "        audio_format='mp3'\n",
    "    )\n",
    "    if extracted_audio:\n",
    "        print(f\"Extracted audio file path: {extracted_audio}\")\n",
    "    else:\n",
    "        print(\"Failed to extract audio.\")\n",
    "else:\n",
    "    print(\"Download step failed. Cannot extract audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send request to sarvam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "\n",
    "def send_to_sarvam_api(audio_file_path, api_key, prompt=None, model='saaras:v1'):\n",
    "    \"\"\"\n",
    "    Sends an audio file to the Sarvam Speech To Text Translate API for transcription.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_file_path (str): Path to the audio file to be transcribed.\n",
    "    - api_key (str): Your Sarvam API subscription key.\n",
    "    - prompt (str, optional): Prompt to assist the transcription.\n",
    "    - model (str, optional): Model to be used. Defaults to 'saaras:v1'.\n",
    "\n",
    "    Returns:\n",
    "    - dict: The API response containing the transcript and language_code.\n",
    "    \"\"\"\n",
    "    url = \"https://api.sarvam.ai/speech-to-text-translate\"\n",
    "\n",
    "    headers = {\n",
    "        'api-subscription-key': api_key\n",
    "    }\n",
    "\n",
    "    # Determine MIME type based on file extension\n",
    "    mime_type, _ = mimetypes.guess_type(audio_file_path)\n",
    "    if mime_type not in ['audio/mpeg', 'audio/wave', 'audio/wav', 'audio/x-wav']:\n",
    "        print(f\"Unsupported audio format: {mime_type}\")\n",
    "        return None\n",
    "\n",
    "    with open(audio_file_path, 'rb') as f:\n",
    "        files = {\n",
    "            'file': (os.path.basename(audio_file_path), f, mime_type)\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "        if prompt:\n",
    "            data['prompt'] = prompt\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, files=files, data=data)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            print(\"API Response:\")\n",
    "            print(result)\n",
    "            return result\n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            print(f\"HTTP error occurred: {http_err} - {response.text}\")\n",
    "        except Exception as err:\n",
    "            print(f\"An error occurred: {err}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response:\n",
      "{'transcript': \"Why is she called a natural star? I am not motivating or inspiring you by telling my personal stories about Nani. It's a waste of time. I am talking about the characters Nani plays, from Ashtachamma to the recent movie Ante Sundarani.\", 'language_code': 'te-IN'}\n",
      "\n",
      "Transcript:\n",
      "Why is she called a natural star? I am not motivating or inspiring you by telling my personal stories about Nani. It's a waste of time. I am talking about the characters Nani plays, from Ashtachamma to the recent movie Ante Sundarani.\n",
      "\n",
      "Detected Language Code: te-IN\n"
     ]
    }
   ],
   "source": [
    "if not SARVAM_KEY:\n",
    "    print(\"Error: SARVAM_KEY environment variable not set.\")\n",
    "    exit(1)\n",
    "\n",
    "    \n",
    "if extracted_audio:\n",
    "    # Step 3: Send to Sarvam API\n",
    "    api_response = send_to_sarvam_api(\n",
    "        extracted_audio,\n",
    "        api_key=SARVAM_KEY,\n",
    "        prompt='This is a telugu audio. Translate it to english',  # Optional: Add any prompt if needed\n",
    "        model='saaras:v1'  # You can change the model if needed\n",
    "    )\n",
    "    \n",
    "    if api_response:\n",
    "        transcript = api_response.get('transcript', '')\n",
    "        language_code = api_response.get('language_code', '')\n",
    "        print(f\"\\nTranscript:\\n{transcript}\\n\")\n",
    "        print(f\"Detected Language Code: {language_code}\")\n",
    "    else:\n",
    "        print(\"API call failed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking into chunks of silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment, silence\n",
    "import os\n",
    "\n",
    "def split_audio_on_silence(input_audio_path, output_dir='audio_chunks', \n",
    "                           min_silence_len=1000, silence_thresh=-40, \n",
    "                           keep_silence=500, max_chunk_duration=7000):\n",
    "    \"\"\"\n",
    "    Splits audio into chunks based on silence and maximum duration.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_audio_path (str): Path to the input audio file.\n",
    "    - output_dir (str): Directory to save the audio chunks.\n",
    "    - min_silence_len (int): Minimum length of silence in ms.\n",
    "    - silence_thresh (int): Silence threshold in dBFS.\n",
    "    - keep_silence (int): Amount of silence to keep at the beginning and end of each chunk in ms.\n",
    "    - max_chunk_duration (int): Maximum duration of each chunk in ms (e.g., 7000 ms for 7 seconds).\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples: Each tuple contains (chunk_path, start_time, end_time)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    \n",
    "    print(\"Splitting audio into chunks based on silence...\")\n",
    "    initial_chunks = silence.split_on_silence(\n",
    "        audio,\n",
    "        min_silence_len=min_silence_len,\n",
    "        silence_thresh=silence_thresh,\n",
    "        keep_silence=keep_silence\n",
    "    )\n",
    "    \n",
    "    final_chunks = []\n",
    "    current_time = 0  # in milliseconds\n",
    "    \n",
    "    for i, chunk in enumerate(initial_chunks):\n",
    "        chunk_duration = len(chunk)\n",
    "        start_time = current_time\n",
    "        end_time = current_time + chunk_duration\n",
    "        \n",
    "        # If chunk is longer than max_chunk_duration, split it further\n",
    "        if chunk_duration > max_chunk_duration:\n",
    "            num_subchunks = chunk_duration // max_chunk_duration + 1\n",
    "            subchunk_duration = chunk_duration / num_subchunks\n",
    "            for j in range(num_subchunks):\n",
    "                sub_start = j * subchunk_duration\n",
    "                sub_end = (j + 1) * subchunk_duration\n",
    "                subchunk = chunk[int(sub_start):int(sub_end)]\n",
    "                \n",
    "                subchunk_filename = f\"chunk_{i+1}_{j+1}.mp3\"\n",
    "                subchunk_path = os.path.join(output_dir, subchunk_filename)\n",
    "                subchunk.export(subchunk_path, format=\"mp3\")\n",
    "                \n",
    "                sub_start_time = start_time + int(sub_start)\n",
    "                sub_end_time = start_time + int(sub_end)\n",
    "                \n",
    "                final_chunks.append((subchunk_path, sub_start_time, sub_end_time))\n",
    "                print(f\"Created {subchunk_filename}: {sub_start_time/1000:.2f}s to {sub_end_time/1000:.2f}s\")\n",
    "                \n",
    "            current_time += chunk_duration + keep_silence\n",
    "        else:\n",
    "            # Export the chunk as is\n",
    "            chunk_filename = f\"chunk_{i+1}.mp3\"\n",
    "            chunk_path = os.path.join(output_dir, chunk_filename)\n",
    "            chunk.export(chunk_path, format=\"mp3\")\n",
    "            \n",
    "            final_chunks.append((chunk_path, start_time, end_time))\n",
    "            print(f\"Created {chunk_filename}: {start_time/1000:.2f}s to {end_time/1000:.2f}s\")\n",
    "            \n",
    "            # Update the current time\n",
    "            current_time = end_time + keep_silence  # Adding kept silence to avoid overlap\n",
    "    \n",
    "    return final_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting audio into chunks based on silence...\n",
      "Created chunk_1_1.mp3: 0.00s to 6.84s\n",
      "Created chunk_1_2.mp3: 6.84s to 13.68s\n",
      "Created chunk_1_3.mp3: 13.68s to 20.52s\n",
      "Created chunk_1_4.mp3: 20.52s to 27.35s\n",
      "Created chunk_1_5.mp3: 27.35s to 34.19s\n",
      "Created chunk_1_6.mp3: 34.19s to 41.03s\n",
      "Created chunk_1_7.mp3: 41.03s to 47.87s\n",
      "Created chunk_1_8.mp3: 47.87s to 54.71s\n",
      "Created chunk_1_9.mp3: 54.71s to 61.55s\n",
      "Created chunk_1_10.mp3: 61.55s to 68.38s\n",
      "Created chunk_1_11.mp3: 68.38s to 75.22s\n",
      "Created chunk_1_12.mp3: 75.22s to 82.06s\n",
      "Created chunk_1_13.mp3: 82.06s to 88.90s\n",
      "Created chunk_1_14.mp3: 88.90s to 95.74s\n",
      "Created chunk_1_15.mp3: 95.74s to 102.58s\n",
      "Created chunk_1_16.mp3: 102.58s to 109.41s\n",
      "Created chunk_1_17.mp3: 109.41s to 116.25s\n",
      "Created chunk_1_18.mp3: 116.25s to 123.09s\n",
      "Created chunk_1_19.mp3: 123.09s to 129.93s\n",
      "Created chunk_1_20.mp3: 129.93s to 136.77s\n",
      "Created chunk_1_21.mp3: 136.77s to 143.60s\n",
      "Created chunk_2.mp3: 144.10s to 147.84s\n",
      "Created chunk_3_1.mp3: 148.34s to 155.05s\n",
      "Created chunk_3_2.mp3: 155.05s to 161.75s\n",
      "Created chunk_3_3.mp3: 161.75s to 168.46s\n",
      "Created chunk_3_4.mp3: 168.46s to 175.16s\n",
      "Created chunk_3_5.mp3: 175.16s to 181.87s\n",
      "Created chunk_3_6.mp3: 181.87s to 188.57s\n",
      "Created chunk_3_7.mp3: 188.57s to 195.28s\n",
      "Created chunk_3_8.mp3: 195.28s to 201.98s\n",
      "Created chunk_3_9.mp3: 201.98s to 208.69s\n",
      "Created chunk_3_10.mp3: 208.69s to 215.39s\n",
      "Created chunk_3_11.mp3: 215.39s to 222.10s\n",
      "Created chunk_3_12.mp3: 222.10s to 228.80s\n",
      "Created chunk_3_13.mp3: 228.80s to 235.51s\n",
      "Created chunk_4_1.mp3: 236.01s to 240.22s\n",
      "Created chunk_4_2.mp3: 240.22s to 244.43s\n"
     ]
    }
   ],
   "source": [
    "if downloaded_audio:\n",
    "    # Split the audio into chunks\n",
    "    chunks = split_audio_on_silence(\n",
    "        downloaded_audio,\n",
    "        output_dir='audio_chunks',\n",
    "        min_silence_len=1000,\n",
    "        silence_thresh=-40,\n",
    "        keep_silence=500\n",
    "    )\n",
    "else:\n",
    "    print(\"Download step failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified sarvam func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_sarvam_api(audio_file_path, api_key, prompt=None, model='saaras:v1'):\n",
    "    \"\"\"\n",
    "    Sends an audio file to the Sarvam Speech To Text Translate API for transcription.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_file_path (str): Path to the audio file to be transcribed.\n",
    "    - api_key (str): Your Sarvam API subscription key.\n",
    "    - prompt (str, optional): Prompt to assist the transcription.\n",
    "    - model (str, optional): Model to be used. Defaults to 'saaras:v1'.\n",
    "\n",
    "    Returns:\n",
    "    - dict: The API response containing the transcript and language_code.\n",
    "    \"\"\"\n",
    "    url = \"https://api.sarvam.ai/speech-to-text-translate\"\n",
    "\n",
    "    headers = {\n",
    "        'api-subscription-key': api_key\n",
    "    }\n",
    "\n",
    "    # Determine MIME type based on file extension\n",
    "    mime_type, _ = mimetypes.guess_type(audio_file_path)\n",
    "    if mime_type not in ['audio/mpeg', 'audio/wave', 'audio/wav', 'audio/x-wav']:\n",
    "        print(f\"Unsupported audio format: {mime_type}\")\n",
    "        return None\n",
    "\n",
    "    with open(audio_file_path, 'rb') as f:\n",
    "        files = {\n",
    "            'file': (os.path.basename(audio_file_path), f, mime_type)\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "        if prompt:\n",
    "            data['prompt'] = prompt\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, files=files, data=data)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            print(f\"Transcription successful for {os.path.basename(audio_file_path)}\")\n",
    "            return result\n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            print(f\"HTTP error occurred for {os.path.basename(audio_file_path)}: {http_err} - {response.text}\")\n",
    "        except Exception as err:\n",
    "            print(f\"An error occurred for {os.path.basename(audio_file_path)}: {err}\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each chunk, collect transcript from sarvam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunks_and_collect_transcripts(chunks, api_key):\n",
    "    \"\"\"\n",
    "    Processes each audio chunk and collects transcripts with timestamps.\n",
    "\n",
    "    Parameters:\n",
    "    - chunks (list): List of tuples containing (chunk_path, start_time, end_time).\n",
    "    - api_key (str): Your Sarvam API subscription key.\n",
    "\n",
    "    Returns:\n",
    "    - List of dictionaries: Each dict contains 'start_time', 'end_time', and 'transcript'.\n",
    "    \"\"\"\n",
    "    transcripts = []\n",
    "    for chunk_path, start_ms, end_ms in chunks:\n",
    "        print(f'Processing chunk: {chunk_path} from {start_ms/1000:.2f}s to {end_ms/1000:.2f}s')\n",
    "        response = send_to_sarvam_api(chunk_path, api_key)\n",
    "        if response and 'transcript' in response:\n",
    "            transcript = response['transcript']\n",
    "            transcripts.append({\n",
    "                'start_time': start_ms,\n",
    "                'end_time': end_ms,\n",
    "                'transcript': transcript\n",
    "            })\n",
    "        else:\n",
    "            transcripts.append({\n",
    "                'start_time': start_ms,\n",
    "                'end_time': end_ms,\n",
    "                'transcript': '[Unintelligible]'\n",
    "            })\n",
    "    return transcripts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format time for format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(ms):\n",
    "    \"\"\"\n",
    "    Formats milliseconds to SRT timestamp format.\n",
    "\n",
    "    Parameters:\n",
    "    - ms (int): Time in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "    - str: Formatted timestamp.\n",
    "    \"\"\"\n",
    "    seconds, milliseconds = divmod(ms, 1000)\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
    "\n",
    "def create_srt_file(transcripts, output_file='subtitles.srt', max_chars=42):\n",
    "    \"\"\"\n",
    "    Creates an SRT file from transcripts with timestamps, ensuring readability.\n",
    "\n",
    "    Parameters:\n",
    "    - transcripts (list): List of dictionaries containing 'start_time', 'end_time', and 'transcript'.\n",
    "    - output_file (str): Path to save the SRT file.\n",
    "    - max_chars (int): Maximum number of characters per subtitle line.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        subtitle_number = 1\n",
    "        for entry in transcripts:\n",
    "            start = format_timestamp(entry['start_time'])\n",
    "            end = format_timestamp(entry['end_time'])\n",
    "            text = entry['transcript'].replace('\\n', ' ').strip()\n",
    "            \n",
    "            # Split text into multiple lines if it exceeds max_chars\n",
    "            lines = []\n",
    "            words = text.split()\n",
    "            current_line = \"\"\n",
    "            for word in words:\n",
    "                if len(current_line) + len(word) + 1 <= max_chars:\n",
    "                    if current_line:\n",
    "                        current_line += ' '\n",
    "                    current_line += word\n",
    "                else:\n",
    "                    lines.append(current_line)\n",
    "                    current_line = word\n",
    "            if current_line:\n",
    "                lines.append(current_line)\n",
    "            \n",
    "            # Combine lines with newline characters\n",
    "            formatted_text = '\\n'.join(lines)\n",
    "            \n",
    "            # Write to SRT\n",
    "            f.write(f\"{subtitle_number}\\n{start} --> {end}\\n{formatted_text}\\n\\n\")\n",
    "            subtitle_number += 1\n",
    "    print(f\"SRT file created at {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk: audio_chunks/chunk_1_1.mp3 from 0.00s to 6.84s\n",
      "Transcription successful for chunk_1_1.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_2.mp3 from 6.84s to 13.68s\n",
      "Transcription successful for chunk_1_2.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_3.mp3 from 13.68s to 20.52s\n",
      "Transcription successful for chunk_1_3.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_4.mp3 from 20.52s to 27.35s\n",
      "Transcription successful for chunk_1_4.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_5.mp3 from 27.35s to 34.19s\n",
      "Transcription successful for chunk_1_5.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_6.mp3 from 34.19s to 41.03s\n",
      "Transcription successful for chunk_1_6.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_7.mp3 from 41.03s to 47.87s\n",
      "Transcription successful for chunk_1_7.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_8.mp3 from 47.87s to 54.71s\n",
      "Transcription successful for chunk_1_8.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_9.mp3 from 54.71s to 61.55s\n",
      "Transcription successful for chunk_1_9.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_10.mp3 from 61.55s to 68.38s\n",
      "Transcription successful for chunk_1_10.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_11.mp3 from 68.38s to 75.22s\n",
      "Transcription successful for chunk_1_11.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_12.mp3 from 75.22s to 82.06s\n",
      "Transcription successful for chunk_1_12.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_13.mp3 from 82.06s to 88.90s\n",
      "Transcription successful for chunk_1_13.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_14.mp3 from 88.90s to 95.74s\n",
      "Transcription successful for chunk_1_14.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_15.mp3 from 95.74s to 102.58s\n",
      "Transcription successful for chunk_1_15.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_16.mp3 from 102.58s to 109.41s\n",
      "Transcription successful for chunk_1_16.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_17.mp3 from 109.41s to 116.25s\n",
      "Transcription successful for chunk_1_17.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_18.mp3 from 116.25s to 123.09s\n",
      "Transcription successful for chunk_1_18.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_19.mp3 from 123.09s to 129.93s\n",
      "Transcription successful for chunk_1_19.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_20.mp3 from 129.93s to 136.77s\n",
      "Transcription successful for chunk_1_20.mp3\n",
      "Processing chunk: audio_chunks/chunk_1_21.mp3 from 136.77s to 143.60s\n",
      "Transcription successful for chunk_1_21.mp3\n",
      "Processing chunk: audio_chunks/chunk_2.mp3 from 144.10s to 147.84s\n",
      "Transcription successful for chunk_2.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_1.mp3 from 148.34s to 155.05s\n",
      "Transcription successful for chunk_3_1.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_2.mp3 from 155.05s to 161.75s\n",
      "Transcription successful for chunk_3_2.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_3.mp3 from 161.75s to 168.46s\n",
      "Transcription successful for chunk_3_3.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_4.mp3 from 168.46s to 175.16s\n",
      "Transcription successful for chunk_3_4.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_5.mp3 from 175.16s to 181.87s\n",
      "Transcription successful for chunk_3_5.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_6.mp3 from 181.87s to 188.57s\n",
      "Transcription successful for chunk_3_6.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_7.mp3 from 188.57s to 195.28s\n",
      "Transcription successful for chunk_3_7.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_8.mp3 from 195.28s to 201.98s\n",
      "Transcription successful for chunk_3_8.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_9.mp3 from 201.98s to 208.69s\n",
      "Transcription successful for chunk_3_9.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_10.mp3 from 208.69s to 215.39s\n",
      "Transcription successful for chunk_3_10.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_11.mp3 from 215.39s to 222.10s\n",
      "Transcription successful for chunk_3_11.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_12.mp3 from 222.10s to 228.80s\n",
      "Transcription successful for chunk_3_12.mp3\n",
      "Processing chunk: audio_chunks/chunk_3_13.mp3 from 228.80s to 235.51s\n",
      "Transcription successful for chunk_3_13.mp3\n",
      "Processing chunk: audio_chunks/chunk_4_1.mp3 from 236.01s to 240.22s\n",
      "Transcription successful for chunk_4_1.mp3\n",
      "Processing chunk: audio_chunks/chunk_4_2.mp3 from 240.22s to 244.43s\n",
      "Transcription successful for chunk_4_2.mp3\n",
      "SRT file created at subtitles.srt\n"
     ]
    }
   ],
   "source": [
    "transcripts = process_chunks_and_collect_transcripts(chunks, SARVAM_KEY)\n",
    "\n",
    "if not transcripts:\n",
    "    print(\"No transcripts collected.\")\n",
    "    \n",
    "\n",
    "create_srt_file(transcripts, output_file='subtitles.srt', max_chars=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
